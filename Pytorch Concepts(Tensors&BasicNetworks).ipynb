{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "#defining the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n",
      "tensor([[0.3177]])\n",
      "tensor([[-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]])\n"
     ]
    }
   ],
   "source": [
    "#generating random data for the model\n",
    "torch.manual_seed(7)\n",
    "#as so things are in range and predictable\n",
    "#and we can regenerate the result\n",
    "\n",
    "features = torch.randn((1,5))\n",
    "weights = torch.randn_like(features)\n",
    "bias = torch.randn((1,1))\n",
    "\n",
    "#for generating random numbers \n",
    "\n",
    "print(features)\n",
    "print(bias)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1595]])\n",
      "tensor([[0.1595]])\n"
     ]
    }
   ],
   "source": [
    "#forming a network by these weights and biases\n",
    "y_a = sigmoid(torch.sum(features*weights)+bias)\n",
    "#2 methods of sum\n",
    "y_b = sigmoid((features*weights).sum()+bias)\n",
    "\n",
    "print(y_a)\n",
    "print(y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1595]])\n"
     ]
    }
   ],
   "source": [
    "#we can do the same thing with matmul operation\n",
    "#first we need to take the transform of the matrix and then perform the matmul operation\n",
    "#there are many ways to reshape the tensor in pytorch\n",
    "#1.reshape\n",
    "#2.resize_(inplace operation)do not make a copy directly change in memory\n",
    "#3.view\n",
    "#best is view\n",
    "y = sigmoid(torch.mm(features,weights.view(5,1))+bias)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1143,  1.6908],\n",
      "        [-0.8948, -0.3556],\n",
      "        [ 1.2324,  0.1382]])\n",
      "tensor([[-1.6822],\n",
      "        [ 0.3177]])\n",
      "tensor([[0.1328, 0.1373]])\n",
      "tensor([[0.2405]])\n"
     ]
    }
   ],
   "source": [
    "#we can do for multilayer preceptrons too\n",
    "##doing multilayer\n",
    "torch.manual_seed(7)\n",
    "features = torch.randn((1,3))\n",
    "#no of inputs must have as same as features number\n",
    "#defining the size of layers\n",
    "n_input = features.shape[1]\n",
    "n_hidden = 2\n",
    "n_output = 1\n",
    "\n",
    "#defining the weights\n",
    "W1 = torch.randn(n_input,n_hidden)\n",
    "W2 = torch.randn(n_hidden,n_output)\n",
    "\n",
    "#defining the bias term\n",
    "B1 = torch.randn(1,n_hidden)\n",
    "B2 = torch.randn(1,n_output)\n",
    "\n",
    "print(W1)\n",
    "print(W2)\n",
    "print(B1)\n",
    "print(B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3171]])\n"
     ]
    }
   ],
   "source": [
    "#making the network\n",
    "h = sigmoid(torch.mm(features,W1)+B1)\n",
    "output = sigmoid(torch.mm(h,W2)+B2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMPY and torch are closely related\n",
    "#we can easily interconvert them and viceversa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31606812, 0.86078419, 0.4595105 ],\n",
       "       [0.02072873, 0.93734627, 0.94025429],\n",
       "       [0.915174  , 0.03690767, 0.37494326],\n",
       "       [0.88085644, 0.96505805, 0.50814503]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(4,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3161, 0.8608, 0.4595],\n",
       "        [0.0207, 0.9373, 0.9403],\n",
       "        [0.9152, 0.0369, 0.3749],\n",
       "        [0.8809, 0.9651, 0.5081]], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31606812, 0.86078419, 0.4595105 ],\n",
       "       [0.02072873, 0.93734627, 0.94025429],\n",
       "       [0.915174  , 0.03690767, 0.37494326],\n",
       "       [0.88085644, 0.96505805, 0.50814503]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6321, 1.7216, 0.9190],\n",
       "        [0.0415, 1.8747, 1.8805],\n",
       "        [1.8303, 0.0738, 0.7499],\n",
       "        [1.7617, 1.9301, 1.0163]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All the things we have done here are inplace and anything we change in numpy change in torch too\n",
    "b.mul_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63213624, 1.72156838, 0.91902099],\n",
       "       [0.04145746, 1.87469254, 1.88050857],\n",
       "       [1.830348  , 0.07381534, 0.74988652],\n",
       "       [1.76171289, 1.93011611, 1.01629006]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
